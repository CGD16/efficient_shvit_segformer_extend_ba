{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR\n",
    "from torchsummary import summary\n",
    "\n",
    "from lightning import Fabric\n",
    "\n",
    "\n",
    "# Set environment variables for PyTorch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Specify which GPU to use, if needed\n",
    "\n",
    "# PyTorch does not have direct equivalents for some TensorFlow environment settings,\n",
    "# but you can manage GPU memory growth and logging through PyTorch\"s API.\n",
    "\n",
    "# Disable debug information (PyTorch does not have a direct equivalent, but you can manage logging)\n",
    "# PyTorch logging can be managed through Python\"s logging module or by setting verbosity levels.\n",
    "\n",
    "# Check if CUDA is available and set device\n",
    "fabric = Fabric(accelerator=\"cuda\", devices=1, precision=\"bf16-true\")\n",
    "fabric.launch()\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# Print PyTorch version\n",
    "print(torch.__version__)\n",
    "\n",
    "# Print number of available GPUs\n",
    "print(\"Num GPUs Available: \", torch.cuda.device_count())\n",
    "\n",
    "# List local devices (PyTorch does not have a direct equivalent, but you can check CUDA devices)\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models_torch.segformer_3d import SegFormer3D_SHViT as SegFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = [20,2000]\n",
    "\n",
    "REPEAT = 5\n",
    "KFOLD = 5\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "N_CONVS = 2\n",
    "N_STAGES = 3\n",
    "BATCH_SIZE = 1\n",
    "ACCUMULATION_STEPS = 5\n",
    "\n",
    "USE_CENTER_ATT = True\n",
    "USE_RESIZE = False\n",
    "KERNEL_SIZE = 3\n",
    "\n",
    "MODEL = \"B5\"\n",
    "SHVIT_TYPE = \"S2\"\n",
    "DATA_NAME = \"SegFormer_2conv\"\n",
    "DEPTH, HEIGHT, WIDTH = 288, 288, 288\n",
    "DIM = f\"{DATA_NAME}_{DEPTH}x{HEIGHT}x{WIDTH}\"\n",
    "MODEL_NAME = f\"CrossVal_SW_VOLUME_{MODEL}_{SHVIT_TYPE}_{DIM}\"\n",
    "\n",
    "\n",
    "train_folder = f\"/mnt/d/Datasets/shoes/images_3d/images_3d_{DIM}/\"\n",
    "valid_folder = f\"/mnt/d/Datasets/shoes/images_3d/images_3d_{DIM}/\"\n",
    "\n",
    "\n",
    "class_dict = {\"Background\": 0, \"Karton\": 1, \"Außensohle\": 2, \"Innensohle\": 3, \"Obermaterial\": 4, \"Zunge\": 5, \"Füllmaterial\": 6}\n",
    "# class_dict = {\"Außensohle\": 1, \"Innensohle\": 2, \"Obermaterial\": 3, \"Füllmaterial\": 4}\n",
    "N_CLASSES = len(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to the different naming of the shoes (images and masks) we have to create a dict to map the images to an unique id\n",
    "\n",
    "shoe_img_dict = {\"Adidas_Martin-weiss\": 1, \"Adidas_Martin\": 2, \n",
    "                 \"Bruschi_down2_2_2\": 3, \"Camper_down2_2_2\": 4, \n",
    "                 \"Citywalk-sit-taupe-34_down2_2_2\": 5, \"Citywalk-sit-taupe-36_down2_2_2\": 6, \n",
    "                 \"Citywalk-sit-taupe-39_down2_2_2\": 7, \"Citywalk-sit-taupe-40_down2_2_2\": 8, \n",
    "                 \"Citywalk-sit-taupe-42_down2_2_2\": 9, \"Herrenschuh_43p5_down2_2_2\": 10, \n",
    "                 \"Lidl_43_down2_2_2\": 11, \"Lloyd_38_down2_2_2\": 12, \n",
    "                 \"Lloyd_pink_down2_2_2\": 13, \"Lloyd_weiss_down2_2_2\": 14, \n",
    "                 \"McKinley_Anton_down2_2_2\": 15, \"Mustang-Sch-Navy-Metalli-35_down2_2_2\": 16, \n",
    "                 \"Mustang-Sch-Navy-Metalli-40_down2_2_2\": 17, \"Mustang-Sch-Navy-Metalli_31_down2_2_2\": 18, \n",
    "                 \"Mustang-Sch-Navy-Metalli_36_down2_2_2\": 19, \"Mustang-Sch-Navy-Metalli_37_down2_2_2\": 20, \n",
    "                 \"Pertolio-dunkelbraun_43_down2_2_2\": 21, \"Petrolio-Sch-dunkelbraun_42_down2_2_2\": 22, \n",
    "                 \"Petrolio-Sch-dunkelbraun_44_down2_2_2\": 23, \"Petrolio-Sch-dunkelbraun_46_down2_2_2\": 24,\n",
    "                 \"PetrolioSch-40-float_down2_2_2\": 25, \"Puma_38_down2_2_2\": 26, \n",
    "                 \"Puma_Silver_down2_2_2\": 27, \"Puma_White_down2_2_2\": 28, \n",
    "                 \"Schuh_Martin_down2_2_2\": 29, \"Shoepassion_40_down2_2_2\": 30, \n",
    "                 \"Shoepassion_45_down2_2_2\": 31, \"Shoepassion_Herren_40_down2_2_2\": 32, \n",
    "                 \"Sneaker_Dana_Nike\": 33, \"Sneaker_Dana_Puma_Flyer\": 34, \n",
    "                 \"Stiefel-XY_40_down2_2_2\": 35, \"Tamaris-Pump-Schwarz-38_down2_2_2\": 36, \n",
    "                 \"Tamaris-Pump-schwarz_36_down2_2_2\": 37, \"Tamaris-Pump-Schwarz_39_down2_2_2\": 38, \n",
    "                 \"Tamaris-Pump-schwarz_40_down2_2_2\": 39, \"Tamaris-Pump-schwarz_42_down2_2_2\": 40}\n",
    "\n",
    "shoe_mask_dict = {\"Adidas_Martin-weiss\": 1, \"Adidas_Martin\": 2, \n",
    "                  \"Bruschi_down2_2_2\": 3, \"Camper_down2_2_2\": 4, \n",
    "                  \"Citywalk 34\": 5, \"Citywalk 36\": 6, \n",
    "                  \"Citywalk 39\": 7, \"Citywalk 40\": 8, \n",
    "                  \"Citywalk 42\": 9, \"Herrenschuh_43p5_down2_2_2\": 10, \n",
    "                  \"Lidl_43_down2_2_2\": 11, \"Lloyd_38_down2_2_2\": 12, \n",
    "                  \"Lloyd_pink_down2_2_2\": 13, \"Lloyd_weiss_down2_2_2\": 14, \n",
    "                  \"McKinley_Anton\": 15, \"Mustang 35\": 16, \n",
    "                  \"Mustang 40\": 17, \"Mustang 31\": 18, \n",
    "                  \"Mustang 36\": 19, \"Mustang 37\": 20, \n",
    "                  \"Petrolio 43\": 21, \"Petrolio 42\": 22, \n",
    "                  \"Petrolio 44\": 23, \"Petrolio 46\": 24, \n",
    "                  \"Petrolio 40\": 25, \"Puma_38_down2_2_2\": 26, \n",
    "                  \"Puma_Silver_down2_2_2\": 27, \"Puma_White_down2_2_2\": 28, \n",
    "                  \"Schuh_Martin_down2_2_2\": 29, \"Shoepassion_40_down2_2_2\": 30, \n",
    "                  \"Shoepassion_45_down2_2_2\": 31, \"Shoepassion_Herren_40_down2_2_2\": 32, \n",
    "                  \"Sneaker_Dana_Nike\": 33, \"Sneaker_Dana_Puma_Flyer\": 34, \n",
    "                  \"StiefelXY\": 35, \"TamarisPump 38\": 36,\n",
    "                  \"TamarisPump 36\": 37, \"TamarisPump 39\": 38, \n",
    "                  \"TamarisPump 40\": 39, \"TamarisPump 42\": 40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(os.path.join(train_folder, \"volumes/*.npy\"))\n",
    "# filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the filenames\n",
    "extracted_filenames = [os.path.basename(filename) for filename in filenames]\n",
    "# print(extracted_filenames)\n",
    "# print(len(extracted_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Dataset):\n",
    "    def __init__(self, filenames=None, folder_path=None, augment=False, **kwargs):\n",
    "        super(DataGenerator, self).__init__(**kwargs)\n",
    "        self.filenames = filenames\n",
    "        self.folder_path = folder_path\n",
    "        self.datalen = len(self.filenames)\n",
    "        self.indexes = np.arange(self.datalen)\n",
    "        self.augment = augment\n",
    "        \n",
    "        \n",
    "    def loadData(self, file):\n",
    "        folder = self.folder_path\n",
    "        \n",
    "        filename_segs = None\n",
    "        fn = os.path.join(folder, f\"volumes/{file}\")\n",
    "            \n",
    "        key = os.path.splitext(file)[0]\n",
    "        if key in shoe_img_dict:\n",
    "            id = shoe_img_dict[key]\n",
    "            for key, value in shoe_mask_dict.items():\n",
    "                if value == id:\n",
    "                    filename_segs = key\n",
    "                    break  \n",
    "                    \n",
    "        segs = os.path.join(folder, f\"masks/{filename_segs}.npy\")\n",
    "            \n",
    "        vol = np.load(fn)\n",
    "        min, max = np.min(vol), np.max(vol)\n",
    "        vol = (vol-min)/(max-min)\n",
    "        segs = np.load(segs)\n",
    "        # if self.augment:\n",
    "        #     v, m = self.random_augment(v, m)\n",
    "            \n",
    "        vol = torch.tensor(vol, dtype=torch.float32).unsqueeze(0)\n",
    "        segs = torch.tensor(segs, dtype=torch.long).unsqueeze(0)\n",
    "        \n",
    "        # Apply augmentation if enabled\n",
    "        if self.augment:\n",
    "            vol, segs = self.random_augment(vol, segs)        \n",
    "            vol = self.adjust_brightness_contrast(vol)            \n",
    "        return vol, segs\n",
    "    \n",
    "    \n",
    "    def random_augment(self, vol, seg):\n",
    "        # Random flip along the depth axis (axis 1)\n",
    "        if random.random() > 0.5:\n",
    "            vol = torch.flip(vol, dims=[1])\n",
    "            seg = torch.flip(seg, dims=[1])\n",
    "        \n",
    "        # Random flip along the height axis (axis 2)\n",
    "        if random.random() > 0.5:\n",
    "            vol = torch.flip(vol, dims=[2])\n",
    "            seg = torch.flip(seg, dims=[2])\n",
    "            \n",
    "        # Random flip along the width axis (axis 3)\n",
    "        if random.random() > 0.5:\n",
    "            vol = torch.flip(vol, dims=[3])\n",
    "            seg = torch.flip(seg, dims=[3])\n",
    "            \n",
    "        # Define the three possible 2D planes for rotation within the 3D volume.\n",
    "        # For a tensor of shape [C, D, H, W]:\n",
    "        #   (1,2): rotation in depth-height plane (i.e., around the width axis)\n",
    "        #   (1,3): rotation in depth-width plane (i.e., around the height axis)\n",
    "        #   (2,3): rotation in height-width plane (i.e., around the depth axis)\n",
    "        planes = [(1, 2), (1, 3), (2, 3)]\n",
    "        \n",
    "        # Choose a random plane and number of 90° rotations (k = 0, 1, 2, or 3)\n",
    "        chosen_plane = random.choice(planes)\n",
    "        k = random.choice([0, 1, 2, 3])\n",
    "        \n",
    "        # Apply the 90° rotation if k is non-zero.\n",
    "        if k:\n",
    "            vol = torch.rot90(vol, k, dims=chosen_plane)\n",
    "            seg = torch.rot90(seg, k, dims=chosen_plane)\n",
    "        \n",
    "        return vol, seg\n",
    "    \n",
    "    \n",
    "    def adjust_brightness_contrast(self, vol): \n",
    "        brightness = random.choice([-0.2,-0.1,0.0,0.1,0.2])\n",
    "        contrast   = random.choice([0.8,0.9,1.0,1.1,1.2,1.3])\n",
    "        \n",
    "        vol = (vol - 0.5) * contrast + 0.5  # Adjust contrast (centered around 0.5)\n",
    "        vol += brightness                   # Add brightness\n",
    "        return np.clip(vol, 0.0, 1.0)       # Clip values to [0, 1] range        \n",
    "            \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        files = np.array(self.filenames)[index]\n",
    "        X, y = self.loadData(files)\n",
    "        return X, y, str(files)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.datalen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_w_augmentation = DataGenerator(filenames=extracted_filenames, folder_path=train_folder, augment=True)\n",
    "dataset_wo_augmentation = DataGenerator(filenames=extracted_filenames, folder_path=train_folder, augment=False)\n",
    "\n",
    "# train_dataloader = DataLoader(train_gen, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_dataloader = DataLoader(val_gen, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# val_iter = iter(val_dataloader)\n",
    "\n",
    "# volumes, segs, filename = next(val_iter)\n",
    "# volumes, segs, filename = next(val_iter)\n",
    "# volumes, segs, filename = next(val_iter)\n",
    "\n",
    "# print(str(filename[0]), volumes.shape, segs.shape)\n",
    "# print(np.unique(segs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def give_color_to_seg_img(seg, n_classes=N_CLASSES):\n",
    "#     # Initialize a tensor for the colored segmentation image with channels first\n",
    "#     seg_img = torch.zeros((3, seg.shape[1], seg.shape[2]), dtype=torch.float32)\n",
    "#     # colors = sns.color_palette(\"hls\", n_classes)\n",
    "#     colors = sns.color_palette(\"rocket\", n_classes)\n",
    "    \n",
    "#     seg = seg.squeeze(0) \n",
    "#     for c in range(n_classes):\n",
    "#         segc = (seg == c)\n",
    "#         seg_img[0,:,:] += segc * colors[c][0]\n",
    "#         seg_img[1,:,:] += segc * colors[c][1]\n",
    "#         seg_img[2,:,:] += segc * colors[c][2]\n",
    "\n",
    "#     return(seg_img)\n",
    "\n",
    "# volumes = volumes.to(\"cpu\")\n",
    "# segs = segs.to(\"cpu\")\n",
    "\n",
    "# idx = 0\n",
    "# volume = volumes[idx].squeeze(0)\n",
    "# seg = segs[idx].squeeze(0)\n",
    "\n",
    "# image = volume[volume.shape[0]//2,:,:]\n",
    "# H, W = image.shape[0], image.shape[1]\n",
    "\n",
    "# seg = seg[seg.shape[0]//2,:,:]\n",
    "# seg = cv2.resize(seg.numpy(), (W, H), interpolation=cv2.INTER_NEAREST) # i.e. StiefelXY: original image and masks have different sizes (968x1130) vs (971x1101) ...\n",
    "# seg = torch.from_numpy(seg).unsqueeze(0)\n",
    "\n",
    "# seg = give_color_to_seg_img(seg)\n",
    "\n",
    "# # Convert tensors to numpy arrays for visualization\n",
    "# image_np = image.numpy()  \n",
    "# seg_np = seg.permute(1, 2, 0).numpy() # Convert from (C, H, W) to (H, W, C)\n",
    "\n",
    "# # Convert tensors to numpy arrays for visualization\n",
    "# masked_image_np = np.stack([image_np] * 3, axis=-1) * 0.5 + seg_np * 0.5\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "# axs[0].imshow(image_np, cmap=\"gray\")\n",
    "# axs[0].set_title(\"Original Image\")\n",
    "# axs[1].imshow(seg_np)\n",
    "# axs[1].set_title(\"Segmentation Mask\")\n",
    "# axs[2].imshow(masked_image_np)\n",
    "# axs[2].set_title(\"Masked Image\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegFormer(model_type=MODEL, shvit_type=SHVIT_TYPE, input_shape=(1, DEPTH, HEIGHT, WIDTH), num_convs=N_CONVS, \n",
    "                  num_stages=N_STAGES, num_classes=N_CLASSES, use_center_att=USE_CENTER_ATT, use_resize=USE_RESIZE, kernel_size=KERNEL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_stats(model):\n",
    "    # Calculate the size for parameters (weights) and buffers\n",
    "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "    total_size_bytes = param_size + buffer_size\n",
    "    total_size_mb = total_size_bytes / (1024 ** 2)\n",
    "\n",
    "    # Count the trainable and non-trainable parameters\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    \n",
    "    return total_size_mb, trainable_params, non_trainable_params\n",
    "\n",
    "# # Example usage:\n",
    "model_size, trainable, non_trainable = get_model_stats(model)\n",
    "print(f\"Model size: {model_size:.2f} MB\")\n",
    "print(f\"Trainable parameters: {trainable}\")\n",
    "print(f\"Non-trainable parameters: {non_trainable}\")\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over the layers of the model\n",
    "# for name, layer in model.named_children():\n",
    "#     print(f\"Layer: {name}\")\n",
    "#     print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    \n",
    "#     for param_name, param in layer.named_parameters(recurse=False):\n",
    "#         print(f\" Weight dtype: {param.dtype} | Weight name: {param_name} | Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torchviz import make_dot\n",
    "\n",
    "# # Forward pass through the model to get the graph\n",
    "# model_output = model(volumes)\n",
    "\n",
    "# # # Generate and save the model graph\n",
    "# model_graph = make_dot(model_output, params=dict(model.named_parameters()))\n",
    "# model_graph.render(f\"segformer_model_structure_{MODEL_NAME}\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over the layers of the model\n",
    "# for name, layer in model.named_children():\n",
    "#     # Check if the layer has parameters and print their trainability status\n",
    "#     has_trainable_params = any(param.requires_grad for param in layer.parameters(recurse=False))\n",
    "#     print(f\"Layer: {name} | Trainable: {has_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true, y_pred, smooth=1e-5, num_classes=N_CLASSES):\n",
    "    # Flatten y_true\n",
    "    y_true = y_true.reshape(-1).float()  # Ensure y_true is float32 and flatten\n",
    "\n",
    "    # Reshape y_pred to match\n",
    "    y_pred = y_pred.permute(0, 2, 3, 4, 1).reshape(-1,num_classes).float()  # (batch_size * height * width, num_classes)\n",
    "\n",
    "    iou_per_class = []\n",
    "    for class_id in range(num_classes):\n",
    "        true_mask = (y_true == class_id).float()  # Binary mask for class\n",
    "        pred_mask = y_pred[:, class_id]  # Softmax probability for class\n",
    "\n",
    "        intersection = torch.sum(true_mask * pred_mask)\n",
    "        union = torch.sum(true_mask) + torch.sum(pred_mask) - intersection\n",
    "\n",
    "        iou = (intersection + smooth) / (union + smooth)\n",
    "        iou_per_class.append(iou)  # Store IoU for each class\n",
    "\n",
    "    return torch.mean(torch.stack(iou_per_class)), iou_per_class\n",
    "\n",
    "def jaccard_distance_loss(y_true, y_pred, smooth=1e-5, num_classes=N_CLASSES):\n",
    "    iou, _ = iou_metric(y_true, y_pred, smooth=smooth, num_classes=num_classes)\n",
    "    return 1 - iou\n",
    "\n",
    "\n",
    "\n",
    "def f1_score_metric(y_true, y_pred, smooth=1e-5, num_classes=N_CLASSES):\n",
    "    y_true = y_true.reshape(-1).float()  # Flatten ground truth\n",
    "    y_pred = y_pred.permute(0, 2, 3, 4, 1).reshape(-1, num_classes).float()  # Reshape prediction\n",
    "\n",
    "    f1_per_class = []\n",
    "    for class_id in range(num_classes):\n",
    "        true_mask = (y_true == class_id).float()\n",
    "        pred_mask = y_pred[:, class_id]\n",
    "\n",
    "        intersection = torch.sum(true_mask * pred_mask)\n",
    "        denominator = torch.sum(true_mask) + torch.sum(pred_mask)\n",
    "\n",
    "        f1 = (2 * intersection + smooth) / (denominator + smooth)\n",
    "        f1_per_class.append(f1)\n",
    "\n",
    "    return torch.mean(torch.stack(f1_per_class)), f1_per_class\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-5, num_classes=N_CLASSES):\n",
    "    f1, _ = f1_score_metric(y_true, y_pred, smooth, num_classes)\n",
    "    return 1 - f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmupSchedulerWithReduceLROnPlateau:\n",
    "    def __init__(self, optimizer, warmup_epochs, initial_lr, target_lr, \n",
    "                 reduce_lr_factor=0.1, min_lr=1e-6, patience=5, monitor=\"val_loss\", mode=\"min\"):\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.initial_lr = initial_lr\n",
    "        self.target_lr = target_lr\n",
    "        self.reduce_lr_factor = reduce_lr_factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.epoch = 0\n",
    "        self.best_metric = np.inf if mode == \"min\" else -np.inf\n",
    "        self.wait = 0\n",
    "        self.last_epoch_metric_value = None\n",
    "        self.new_lr = None\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = initial_lr\n",
    "\n",
    "    def on_epoch_begin(self, epoch):\n",
    "        if epoch <= self.warmup_epochs:\n",
    "            # Linear warm-up\n",
    "            self.new_lr = self.initial_lr + (self.target_lr - self.initial_lr) * (epoch / self.warmup_epochs)\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group[\"lr\"] = self.new_lr\n",
    "            # print(f\"Warmup: Setting LR to {self.new_lr:.8f}\")\n",
    "        else:\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                self.new_lr = param_group[\"lr\"]\n",
    "            # print(f\"Training: LR = {self.new_lr:.8f} ({self.wait})\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.epoch += 1\n",
    "        metric_value = logs.get(self.monitor)\n",
    "\n",
    "        if metric_value is None:\n",
    "            return\n",
    "\n",
    "        if epoch > self.warmup_epochs:\n",
    "            if (self.mode == \"min\" and metric_value < self.best_metric) or (self.mode == \"max\" and metric_value > self.best_metric):\n",
    "                self.best_metric = metric_value\n",
    "                self.wait = 0  # Reset patience counter\n",
    "                # print(f\"\\nwait (after if): {self.wait}\")\n",
    "            else:\n",
    "                self.wait += 1\n",
    "                # print(f\"\\nwait (after else): {self.wait}\")\n",
    "                if self.wait >= self.patience:\n",
    "                    self.new_lr = max(self.new_lr * self.reduce_lr_factor, self.min_lr)\n",
    "                    for param_group in self.optimizer.param_groups:\n",
    "                        param_group[\"lr\"] = self.new_lr\n",
    "                    # print(f\"ReduceLROnPlateau: Reducing LR to {self.new_lr:.8f}\")\n",
    "                    self.wait = 0  # Reset patience counter\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=40, monitor=\"val_loss\", mode=\"min\"):\n",
    "        self.patience = patience\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_value = np.inf if mode == \"min\" else -np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, logs):\n",
    "        monitor_value = logs.get(self.monitor)\n",
    "        if self.mode == \"min\":\n",
    "            if monitor_value < self.best_value:\n",
    "                self.best_value = monitor_value\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "        else:\n",
    "            if monitor_value > self.best_value:\n",
    "                self.best_value = monitor_value\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "\n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "            \n",
    "\n",
    "class CSVLogger:\n",
    "    def __init__(self, filepath, append=False):\n",
    "        self.filepath = filepath\n",
    "        if not append and os.path.isfile(filepath):\n",
    "            os.remove(filepath)\n",
    "        self.file = open(filepath, \"a\", newline=\"\")\n",
    "        self.writer = csv.writer(self.file)\n",
    "        self.write_header = True        \n",
    "\n",
    "    def close(self, logs=None):\n",
    "        self.file.close()\n",
    "\n",
    "    def __call__(self, epoch=None, logs=None):\n",
    "        if self.write_header:\n",
    "            self.writer.writerow([\"epoch\"] + list(logs.keys()))\n",
    "            self.write_header = False\n",
    "        self.writer.writerow([epoch] + list(logs.values()))\n",
    "        self.file.flush()  # Ensure data is written immediately\n",
    "\n",
    "        \n",
    "        \n",
    "class ModelCheckpoint:\n",
    "    def __init__(self, filepath, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1):\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.save_best_only = save_best_only\n",
    "        self.verbose = verbose\n",
    "        self.best_value = None\n",
    "        if self.mode == \"min\":\n",
    "            self.best_value = np.inf\n",
    "        else:\n",
    "            self.best_value = -np.inf\n",
    "\n",
    "    def __call__(self, model, optimizer, epoch, loss, logs):\n",
    "        monitor_value = logs.get(self.monitor)\n",
    "        \n",
    "        def model_save(epoch, model, optimizer, loss, filename):\n",
    "            torch.save(\n",
    "            {\n",
    "                'epoch': epoch, \n",
    "                'model_state_dict': model.state_dict(), \n",
    "                'optimizer_state_dict':  optimizer.state_dict(),\n",
    "                'loss': loss, \n",
    "            }, filename)\n",
    "    \n",
    "        if not self.save_best_only:\n",
    "            model_save(epoch, model, optimizer, loss, self.filepath)\n",
    "            if self.verbose:\n",
    "                # print(f\"\\tModel saved to {self.filepath}\")\n",
    "                pass\n",
    "            return\n",
    "\n",
    "        if self.mode == \"min\":\n",
    "            if monitor_value < self.best_value:\n",
    "                self.best_value = monitor_value\n",
    "                model_save(epoch, model, optimizer, loss, self.filepath)\n",
    "                if self.verbose:\n",
    "                    # print(f\"\\tModel improved, saving to {self.filepath}\")\n",
    "                    pass\n",
    "        else:\n",
    "            if monitor_value > self.best_value:\n",
    "                self.best_value = monitor_value\n",
    "                model_save(epoch, model, optimizer, loss, self.filepath)\n",
    "                if self.verbose:\n",
    "                    # print(f\"\\tModel improved, saving to {self.filepath}\")\n",
    "                    pass                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  # Start with small LR\n",
    "\n",
    "\n",
    "# scheduler = WarmupSchedulerWithReduceLROnPlateau(optimizer=optimizer, warmup_epochs=EPOCHS[0], \n",
    "#                                                  initial_lr=1e-8, target_lr=LEARNING_RATE, reduce_lr_factor=0.5, min_lr=1e-8,\n",
    "#                                                  patience=15, monitor=\"val_dice_loss\", mode=\"min\")\n",
    "# early_stopping = EarlyStopping(patience=40, monitor=\"val_dice_loss\", mode=\"min\")\n",
    "# csv_logger = CSVLogger(filepath=f\"{MODEL_NAME}_training.log\", append=False)\n",
    "# checkpoint = ModelCheckpoint(filepath=f\"seg_model_{MODEL_NAME}.pkl\", monitor=\"val_dice_loss\", mode=\"min\", save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_class, optimizer_org, dataset_w_augmentation=dataset_w_augmentation, dataset_wo_augmentation=dataset_wo_augmentation, k=5, warmup = 5, num_epochs=5, target_lr=LEARNING_RATE, batch_size=BATCH_SIZE, accumulator_steps=ACCUMULATION_STEPS):\n",
    "    \n",
    "    max_grad_norm = 1.0    \n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    digits = 5\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset_w_augmentation)):\n",
    "        # print(f\"Fold {fold + 1}\")\n",
    "        \n",
    "        # Create data loaders for the current fold\n",
    "        train_subset = Subset(dataset_w_augmentation, train_ids)\n",
    "        val_subset = Subset(dataset_wo_augmentation, val_ids)\n",
    "        \n",
    "        train_dataloader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "        \n",
    "        train_dataloader = fabric.setup_dataloaders(train_dataloader)\n",
    "        val_dataloader = fabric.setup_dataloaders(val_dataloader)\n",
    "\n",
    "        # Initialize a new model for each fold\n",
    "        model = model_class()\n",
    "        optimizer = optimizer_org(model)\n",
    "        model, optimizer = fabric.setup(model, optimizer)\n",
    "        \n",
    "        scheduler = WarmupSchedulerWithReduceLROnPlateau(optimizer=optimizer, warmup_epochs=warmup, \n",
    "                                                        initial_lr=1e-8, target_lr=target_lr, reduce_lr_factor=0.5, min_lr=1e-8,\n",
    "                                                        patience=15, monitor=\"val_dice_loss\", mode=\"min\")\n",
    "        early_stopping = EarlyStopping(patience=40, monitor=\"val_dice_loss\", mode=\"min\")\n",
    "        \n",
    "        \n",
    "        best_train_iou, best_train_jaccard_loss = -np.inf, np.inf\n",
    "        best_val_iou, best_val_jaccard_loss = -np.inf, np.inf\n",
    "        best_train_f1, best_train_dice_loss = -np.inf, np.inf\n",
    "        best_val_f1, best_val_dice_loss = -np.inf, np.inf            \n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            # print(epoch)\n",
    "    \n",
    "            # At the beginning of the epoch, update the LR if in warmup phase\n",
    "            scheduler.on_epoch_begin(epoch=epoch)\n",
    "            \n",
    "            train_iou, train_jaccard_loss = 0, 0\n",
    "            val_iou, val_jaccard_loss = 0, 0\n",
    "            train_f1, train_dice_loss = 0, 0\n",
    "            val_f1, val_dice_loss = 0, 0\n",
    "\n",
    "            step = 0\n",
    "            \n",
    "            # with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{EPOCHS[1]}\", unit=\"batch\", colour=\"yellow\", leave=True) as pbar:    \n",
    "\n",
    "            model.train()  # Set the model to training mode\n",
    "            for batch_idx, (vols, segs, _) in enumerate(train_dataloader):\n",
    "                step += 1\n",
    "                \n",
    "                output = model(vols)\n",
    "                loss_jaccard = jaccard_distance_loss(segs, output)\n",
    "                loss_dice = dice_loss(segs, output)\n",
    "                train_jaccard_loss += loss_jaccard.item()\n",
    "                train_dice_loss += loss_dice.item()\n",
    "                \n",
    "                fabric.backward(loss_dice)\n",
    "\n",
    "                if (batch_idx + 1) % accumulator_steps == 0:\n",
    "                    clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()  \n",
    "\n",
    "                # Update progress bar\n",
    "                # pbar.set_postfix(loss=f\"{train_jaccard_loss / min(step*BATCH_SIZE, len(train_dataloader)):.4f}\")\n",
    "                # pbar.update(1)\n",
    "\n",
    "            train_jaccard_loss /= len(train_dataloader)\n",
    "            train_iou = 1 - train_jaccard_loss\n",
    "            \n",
    "            train_dice_loss /= len(train_dataloader)\n",
    "            train_f1 = 1 - train_dice_loss\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            with torch.no_grad():\n",
    "                for vols, segs, _ in val_dataloader:\n",
    "                    output = model(vols)\n",
    "                    loss_jaccard = jaccard_distance_loss(segs, output)\n",
    "                    loss_dice = dice_loss(segs, output)\n",
    "                    val_jaccard_loss += loss_jaccard.item()\n",
    "                    val_dice_loss += loss_dice.item()\n",
    "\n",
    "            val_jaccard_loss /= len(val_dataloader)\n",
    "            val_iou = 1 - val_jaccard_loss\n",
    "                \n",
    "            val_dice_loss /= len(val_dataloader)\n",
    "            val_f1 = 1 - val_dice_loss        \n",
    "                \n",
    "            # Callbacks for CSV_logger\n",
    "            logs = {\n",
    "                \"train_jaccard_loss\": train_jaccard_loss,\n",
    "                \"train_iou\": train_iou,\n",
    "                \"val_jaccard_loss\": val_jaccard_loss,\n",
    "                \"val_iou\": val_iou,\n",
    "                \"train_dice_loss\": train_dice_loss,\n",
    "                \"train_f1\": train_f1,\n",
    "                \"val_dice_loss\": val_dice_loss,\n",
    "                \"val_f1\": val_f1,\n",
    "            }    \n",
    "            \n",
    "            \n",
    "            best_train_iou = max(best_train_iou, train_iou)\n",
    "            best_train_jaccard_loss = min(best_train_jaccard_loss, train_jaccard_loss)\n",
    "            best_val_iou = max(best_val_iou, val_iou)\n",
    "            best_val_jaccard_loss = min(best_val_jaccard_loss, val_jaccard_loss)\n",
    "            best_train_f1 = max(best_train_f1, train_f1)\n",
    "            best_train_dice_loss = min(best_train_dice_loss, train_dice_loss)\n",
    "            best_val_f1 = max(best_val_f1, val_f1)\n",
    "            best_val_dice_loss = min(best_val_dice_loss, val_dice_loss)\n",
    "    \n",
    "            bestlogs = {\n",
    "                \"train_jaccard_loss\": round(best_train_jaccard_loss, digits),\n",
    "                \"train_iou\": round(best_train_iou, digits),\n",
    "                \"val_jaccard_loss\": round(best_val_jaccard_loss, digits),\n",
    "                \"val_iou\": round(best_val_iou, digits),\n",
    "                \"train_dice_loss\": round(best_train_dice_loss, digits),\n",
    "                \"train_f1\": round(best_train_f1, digits),\n",
    "                \"val_dice_loss\": round(best_val_dice_loss, digits),\n",
    "                \"val_f1\": round(best_val_f1, digits),\n",
    "            }   \n",
    "            \n",
    "            # At the end of the epoch, update the scheduler with the logs\n",
    "            scheduler.on_epoch_end(epoch=epoch+1, logs=logs)    \n",
    "            \n",
    "            # Check if early stopping condition is met\n",
    "            early_stopping(logs=logs)    \n",
    "            if early_stopping.early_stop:\n",
    "                # print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break    \n",
    "\n",
    "        fold_results.append(bestlogs)\n",
    "        # print(bestlogs)\n",
    "            \n",
    "    return fold_results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for repeat in range(REPEAT):\n",
    "    \n",
    "    start = time.time()\n",
    "    # model_class and optimizer_org with lambda function to make reset of model/optimizer in function cross_validation() possible\n",
    "    results = cross_validation(model_class = lambda: SegFormer(model_type=MODEL, shvit_type=SHVIT_TYPE, input_shape=(1, DEPTH, HEIGHT, WIDTH), \n",
    "                                                               num_convs=N_CONVS, num_stages=N_STAGES, num_classes=N_CLASSES, \n",
    "                                                               use_center_att=USE_CENTER_ATT, use_resize=USE_RESIZE, kernel_size=KERNEL_SIZE), \n",
    "                               optimizer_org = lambda model: torch.optim.Adam(model.parameters(), lr=LEARNING_RATE), \n",
    "                               dataset_w_augmentation=dataset_w_augmentation, dataset_wo_augmentation=dataset_wo_augmentation, \n",
    "                               k=KFOLD, warmup=EPOCHS[0], num_epochs=EPOCHS[1], \n",
    "                               target_lr=LEARNING_RATE, batch_size=BATCH_SIZE, accumulator_steps=ACCUMULATION_STEPS)\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    mean_results = df.mean()  # Returns a Series with the mean of each column\n",
    "\n",
    "    print(f\"Memory used: {torch.cuda.max_memory_reserved() / 1e9:.02f} GB\")\n",
    "    print(f\"Time elapsed {elapsed/60:.2f} min\")\n",
    "    print(mean_results[[\"val_iou\", \"val_f1\"]])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Clean up after each run\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestmodel = SegFormer(model_type=MODEL, shvit_type=SHVIT_TYPE, input_shape=(1, DEPTH, HEIGHT, WIDTH), num_convs=N_CONVS, num_stages=N_STAGES, num_classes=N_CLASSES, use_center_att=USE_CENTER_ATT, use_resize=USE_RESIZE, kernel_size=KERNEL_SIZE)\n",
    "\n",
    "# checkpoint = torch.load(f\"seg_model_{MODEL_NAME}.pkl\", map_location=torch.device(\"cuda\"))  # or map to device if needed\n",
    "# print(checkpoint.keys())\n",
    "# bestmodel.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# bestmodel = fabric.setup(bestmodel) # Move the model to the appropriate device (GPU if available)\n",
    "\n",
    "# test_gen = DataGenerator(filenames=extracted_filenames, folder_path=valid_folder, augment=False)\n",
    "# test_dataloader = DataLoader(test_gen, batch_size=1, shuffle=False)\n",
    "# test_dataloader = fabric.setup_dataloaders(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_iou_scores = []\n",
    "# iou_class_scores = []\n",
    "\n",
    "# avg_f1_scores = []\n",
    "# f1_class_scores = []\n",
    "\n",
    "# test_iter = iter(test_dataloader)\n",
    "\n",
    "# for i in range(40):\n",
    "#     vol, seg, filename = next(test_iter)\n",
    "    \n",
    "#     bestmodel.eval()\n",
    "#     with torch.no_grad():\n",
    "#         pred = bestmodel(vol)#.cpu().detach().numpy()\n",
    "    \n",
    "#     avg, f1 = f1_score_metric(seg.cpu(), pred.cpu(), smooth=1e-5, num_classes=N_CLASSES)\n",
    "#     print(\"F1: \", avg.item(), torch.stack(f1).cpu().numpy())\n",
    "#     avg_f1_scores.append(avg.item())  # scalar float\n",
    "#     f1_class_scores.append(torch.stack(f1).cpu().numpy())  # numpy array per sample    \n",
    "\n",
    "#     avg, iou = iou_metric(seg.cpu(), pred.cpu(), smooth=1e-5, num_classes=N_CLASSES)\n",
    "#     print(\"IoU: \", avg.item(), torch.stack(iou).cpu().numpy())\n",
    "#     avg_iou_scores.append(avg.item())  # scalar float\n",
    "#     iou_class_scores.append(torch.stack(iou).cpu().numpy())  # numpy array per sample    \n",
    "    \n",
    "\n",
    "#     vol = vol[0].squeeze(0).cpu().detach().numpy()\n",
    "#     seg = seg[0].squeeze(0).cpu().detach().numpy()\n",
    "#     pred = pred.cpu().detach().numpy()\n",
    "\n",
    "#     print(str(filename[0]))\n",
    "#     print(vol.shape, seg.shape, pred[0].shape)\n",
    "    \n",
    "#     image = vol[vol.shape[0]//2,:,:]\n",
    "#     H, W = image.shape[0], image.shape[1]    \n",
    "#     seg = seg[seg.shape[0]//2,:,:]\n",
    "\n",
    "\n",
    "#     pred = np.argmax(pred[0], axis=0)\n",
    "#     pred = pred[pred.shape[0]//2,:,:]\n",
    "  \n",
    "#     seg = cv2.resize(seg, (W, H), interpolation=cv2.INTER_NEAREST) # i.e. StiefelXY: original image and masks have different sizes (968x1130) vs (971x1101) ...\n",
    "#     pred = cv2.resize(pred, (W, H), interpolation=cv2.INTER_NEAREST) # i.e. StiefelXY: original image and masks have different sizes (968x1130) vs (971x1101) ...\n",
    "    \n",
    "#     seg = torch.from_numpy(seg).unsqueeze(0)\n",
    "#     pred = torch.from_numpy(pred).unsqueeze(0)\n",
    "\n",
    "#     _s = give_color_to_seg_img(seg).permute(1, 2, 0).numpy()\n",
    "#     _p = give_color_to_seg_img(pred).permute(1, 2, 0).numpy()\n",
    "    \n",
    "#     # Convert tensors to numpy arrays for visualization\n",
    "#     image = image\n",
    "#     predimg = cv2.addWeighted(np.stack([image]*3, axis=-1), 0.15, _p, 0.85, 0)\n",
    "#     trueimg = cv2.addWeighted(np.stack([image]*3, axis=-1), 0.15, _s, 0.85, 0)\n",
    "    \n",
    "#     plt.figure(figsize=(12, 4))\n",
    "#     plt.subplot(131)\n",
    "#     plt.title(\"Original\")\n",
    "#     plt.imshow(image, cmap=\"gray\")\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "#     plt.subplot(132)\n",
    "#     plt.title(\"Prediction\")\n",
    "#     plt.imshow(predimg)\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "#     plt.subplot(133)\n",
    "#     plt.title(\"Ground truth\")\n",
    "#     plt.imshow(trueimg)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.tight_layout()\n",
    "#     # plt.savefig(\"pred_\"+str(i)+\".png\", dpi=150)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "# # Average overall IoU/F1\n",
    "# avg_iou_overall = sum(avg_iou_scores) / len(avg_iou_scores)\n",
    "# avg_f1_overall = sum(avg_f1_scores) / len(avg_f1_scores)\n",
    "\n",
    "# # Average per-class IoU/F1\n",
    "# iou_class_scores_np = np.stack(iou_class_scores)  # shape: [num_samples, num_classes]\n",
    "# avg_iou_per_class = np.mean(iou_class_scores_np, axis=0)    \n",
    "# std_iou_per_class = np.std(iou_class_scores_np, axis=0)\n",
    "# f1_class_scores_np = np.stack(f1_class_scores)  # shape: [num_samples, num_classes]\n",
    "# avg_f1_per_class = np.mean(f1_class_scores_np, axis=0)    \n",
    "# std_f1_per_class = np.std(f1_class_scores_np, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(class_dict)\n",
    "\n",
    "# print(f\"Average Overall IoU Score: {avg_iou_overall:.4f}\")\n",
    "# print(f\"Average Per-Class IoU Scores: {[\"{:.4f}\".format(x) for x in avg_iou_per_class]}\")\n",
    "# print(f\"Standard-Deviation Per-Class IoU Scores: {[\"{:.4f}\".format(x) for x in std_iou_per_class]}\")\n",
    "\n",
    "# print(f\"Average Overall F1 Score: {avg_f1_overall:.4f}\")\n",
    "# print(f\"Average Per-Class F1 Scores: {[\"{:.4f}\".format(x) for x in avg_f1_per_class]}\")\n",
    "# print(f\"Standard-Deviation Per-Class F1 Scores: {[\"{:.4f}\".format(x) for x in std_f1_per_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch260",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
